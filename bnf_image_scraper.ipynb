{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5555c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c759fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert total number of pages(with 50 images in each page): 10\n",
      "Insert term to search images for: Mai 1968\n"
     ]
    }
   ],
   "source": [
    "num_page= int(input(\"Insert total number of pages(with 50 images in each page): \"))\n",
    "num_page+=1\n",
    "url_start= 'https://gallica.bnf.fr/services/engine/search/sru?operation=searchRetrieve&version=1.2&startRecord='\n",
    "url_middle='&maximumRecords=50&page='\n",
    "search_term= str(input(\"Insert term to search images for: \"))\n",
    "url_end= f'&query=(gallica all \"{search_term}\")'\n",
    "filter_end= '&filter=dc.type all \"image\"'\n",
    "\n",
    "final_urls=[]\n",
    "\n",
    "start_rec=0\n",
    "for search in range(1,num_page):\n",
    "    final_search=str(url_start+str(start_rec)+url_middle+str(search)+url_end+filter_end)\n",
    "    start_rec+=50\n",
    "    reqs = requests.get(final_search)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    prefix= 'https://gallica.bnf.fr/ark:'\n",
    "    txt= '(?:(?:https?):\\/\\/)?[\\w/\\-?=%.]+\\.highres'\n",
    "    for url in re.findall(txt,str(soup)):\n",
    "        suffix= url.replace(\".\",\"/f1.\")\n",
    "        all_together= prefix+suffix\n",
    "        final_urls.append(all_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde34b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopped at Retrieve&version=1.2&startRecord=25550&maximumRecords=50&page=511&query= Mai 1968 Le Front populaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e608e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term=search_term.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7de9163f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(final_urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88109eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_urls=list(set(final_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51388b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(os.getcwd(),\"images_from_the_past\",'FRANCE',search_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f9fb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "final_df= pd.DataFrame()\n",
    "col_name= 'bnf_gallica_'+search_term\n",
    "final_df[col_name]= final_urls\n",
    "csv_name= col_name+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb6d7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join(os.getcwd(),\"images_from_the_past\",'FRANCE',csv_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3a0fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ee5f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url= 'https://gallica.bnf.fr/ark:/12148/btv1b9018124t/f1.highres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3942e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in final_urls:\n",
    "    ## Set up the image URL and filename\n",
    "    image_url = url\n",
    "    filename = image_url.split(\"/\")[-2]+\".jpg\"\n",
    "    filename=filename.replace(\"/\",\"_\")\n",
    "    filename= os.path.join(os.getcwd(),\"images_from_the_past\",'FRANCE',search_term,filename)\n",
    "    # Open the url image, set stream to True, this will return the stream content.\n",
    "    r = requests.get(image_url, stream = True)\n",
    "\n",
    "    # Check if the image was retrieved successfully\n",
    "    if r.status_code == 200:\n",
    "        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        r.raw.decode_content = True\n",
    "\n",
    "        # Open a local file with wb ( write binary ) permission.\n",
    "        with open(filename,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    #     print('Image sucessfully Downloaded: ',filename)\n",
    "    else:\n",
    "        print('Image Couldn\\'t be retreived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "18c62123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wget\n",
    "\n",
    "# initial = 'https://gallica.bnf.fr/ark:/12148/btv1b9027504d.r=manifestations?rk=171674;4'\n",
    "\n",
    "# text_split = initial.split('.')\n",
    "# initial_no_end = initial.replace(text_split[-1],'')\n",
    "# old = '.'\n",
    "# new = '/f'\n",
    "# maxreplace = 1\n",
    "\n",
    "# result = new.join(initial_no_end.rsplit(old, maxreplace))\n",
    "\n",
    "# result\n",
    "\n",
    "# fraum = 1 # 1st page to download\n",
    "# tou = 5 # Last page to download (overshoot is not an issue, will just add blank files)\n",
    "# part1 = result  # exemple: couper la zone apr√®s f (folio ?) '4.highres' 'https://gallica.bnf.fr/ark:/12148/bpt6k408619m/f4.highres'\n",
    "\n",
    "# while fraum <= tou:\n",
    "#     no = str(fraum)\n",
    "#     part2 = '.highres'\n",
    "#     noext = no + \".jpg\"\n",
    "#     fraum = fraum + 1\n",
    "#     image_url = part1 + no + part2\n",
    "#     print('\\r\\npage ', fraum, '/', tou)\n",
    "#     local_image_filename = wget.download(image_url, out=noext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
