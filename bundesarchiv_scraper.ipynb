{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3412b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a85f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert term from whose search the results will be scraped: Nationalsozialistische\n",
      "Insert total number of pages for the search term: 171\n",
      "Image URLs extracted...\n"
     ]
    }
   ],
   "source": [
    "final_urls=[]\n",
    "\n",
    "url_start='https://www.bild.bundesarchiv.de/dba/en/search/?yearfrom=&yearto=&query='\n",
    "final_search= str(input(\"Insert term from whose search the results will be scraped: \"))\n",
    "search_term= final_search\n",
    "url_end='&page='\n",
    "num_page= int(input(\"Insert total number of pages for the search term: \"))\n",
    "num_page+=1\n",
    "for search in range(1,num_page):\n",
    "    final_search=str(url_start+final_search+url_end+str(search))\n",
    "    reqs = requests.get(final_search)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    txt= '(?:(?:https?):\\/\\/)?[\\w/\\-?=%.]+\\.jpg'\n",
    "    for url in re.findall(txt,str(soup)):\n",
    "        final_urls.append(url)\n",
    "\n",
    "print(\"Image URLs extracted...\")\n",
    "final_df= pd.DataFrame()\n",
    "final_df['site_images']= final_urls\n",
    "final_df= final_df[final_df['site_images'].str.contains('https://bild.bundesarchiv.de/device_barch')==True]\n",
    "final_df= final_df.drop_duplicates()\n",
    "csv_name= search_term+\"_image_urls\"+\".csv\"\n",
    "final_df.to_csv(csv_name,index=False)\n",
    "final_urls= final_df['site_images'].to_list()\n",
    "\n",
    "search_term= search_term.replace(' ','')\n",
    "search_term=search_term.replace(',','')\n",
    "os.mkdir(os.path.join(os.getcwd(),\"images_from_the_past\",'Bundesarchiv',search_term))\n",
    "\n",
    "for url in final_urls:\n",
    "    try:\n",
    "        image_url = url\n",
    "        filename = image_url.split(\"/\")[-1]\n",
    "        filename=filename.replace(\"/\",\"_\")\n",
    "        filename= os.path.join(os.getcwd(),\"images_from_the_past\",'Bundesarchiv',search_term,filename)\n",
    "        r = requests.get(image_url, stream = True)\n",
    "\n",
    "        # Check if the image was retrieved successfully\n",
    "        if r.status_code == 200:\n",
    "            # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "            r.raw.decode_content = True\n",
    "\n",
    "            # Open a local file with wb ( write binary ) permission.\n",
    "            with open(filename,'wb') as f:\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "        else:\n",
    "            print('Image Couldn\\'t be retreived')\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
